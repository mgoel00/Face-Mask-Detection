{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1320 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "img_rows, img_cols = 48,48\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = './datasets/train'\n",
    "validation_data_dir = './datasets/validation'\n",
    "\n",
    "# Let's use some data augmentation and define our generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "train_images = train_generator.samples\n",
    "validation_images = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'with_mask', 1: 'without_mask'}\n"
     ]
    }
   ],
   "source": [
    "#Make a dictionary for later use in predictions\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,253,730\n",
      "Trainable params: 1,253,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Let us create our model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding = 'same',input_shape=(img_rows,img_cols,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 0.6966 - acc: 0.5656 - val_loss: 0.6717 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67165, saving model to mask_detector.h5\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 0.6157 - acc: 0.7005 - val_loss: 0.3281 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67165 to 0.32809, saving model to mask_detector.h5\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.5442 - acc: 0.7706 - val_loss: 0.2260 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32809 to 0.22598, saving model to mask_detector.h5\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 16s 191ms/step - loss: 0.4202 - acc: 0.8300 - val_loss: 0.0805 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22598 to 0.08052, saving model to mask_detector.h5\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.3789 - acc: 0.8590 - val_loss: 0.1718 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08052\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 16s 190ms/step - loss: 0.3085 - acc: 0.8849 - val_loss: 0.1793 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08052\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.2156 - acc: 0.9276 - val_loss: 0.0474 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08052 to 0.04744, saving model to mask_detector.h5\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.1512 - acc: 0.9581 - val_loss: 0.0530 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04744\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 16s 193ms/step - loss: 0.1526 - acc: 0.9505 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04744 to 0.02957, saving model to mask_detector.h5\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.1378 - acc: 0.9505 - val_loss: 0.0709 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02957\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.1223 - acc: 0.9611 - val_loss: 0.0576 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02957\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 16s 192ms/step - loss: 0.1262 - acc: 0.9588 - val_loss: 0.0479 - val_acc: 0.9792\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02957\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Training our model\n",
    "#This model has been trained only for one epoch. One could do some tweakings!\n",
    "from keras.optimizers import RMSprop, SGD,Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"mask_detector.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "nb_train_samples = train_images\n",
    "nb_validation_samples = validation_images\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = RMSprop(0.001),\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our model\n",
    "from keras.models import load_model\n",
    "classifier = load_model('mask_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2065365 0.7934635]\n",
      "without_mask\n",
      "[0.20390283 0.79609716]\n",
      "without_mask\n",
      "[0.20927751 0.7907225 ]\n",
      "without_mask\n",
      "[0.22880322 0.7711968 ]\n",
      "without_mask\n",
      "[0.22098978 0.77901024]\n",
      "without_mask\n",
      "[0.21871413 0.7812859 ]\n",
      "without_mask\n",
      "[0.22765528 0.7723447 ]\n",
      "without_mask\n",
      "[0.22780749 0.7721925 ]\n",
      "without_mask\n",
      "[0.2327372 0.7672628]\n",
      "without_mask\n",
      "[0.23141903 0.768581  ]\n",
      "without_mask\n",
      "[0.2268251 0.7731749]\n",
      "without_mask\n",
      "[0.21381614 0.7861839 ]\n",
      "without_mask\n",
      "[0.23821789 0.76178217]\n",
      "without_mask\n",
      "[0.21517904 0.7848209 ]\n",
      "without_mask\n",
      "[0.22794914 0.7720509 ]\n",
      "without_mask\n",
      "[0.23563401 0.764366  ]\n",
      "without_mask\n",
      "[0.22540908 0.77459097]\n",
      "without_mask\n",
      "[0.2277178 0.7722822]\n",
      "without_mask\n",
      "[0.21367157 0.7863284 ]\n",
      "without_mask\n",
      "[0.22511165 0.77488834]\n",
      "without_mask\n",
      "[0.22859232 0.77140766]\n",
      "without_mask\n",
      "[0.23085694 0.76914304]\n",
      "without_mask\n",
      "[0.22225648 0.7777435 ]\n",
      "without_mask\n",
      "[0.21932782 0.78067213]\n",
      "without_mask\n",
      "[0.2112049 0.7887951]\n",
      "without_mask\n",
      "[0.2219059 0.7780941]\n",
      "without_mask\n",
      "[0.2167231 0.7832769]\n",
      "without_mask\n",
      "[0.2260017  0.77399826]\n",
      "without_mask\n",
      "[0.22333567 0.77666426]\n",
      "without_mask\n",
      "[0.22724238 0.77275765]\n",
      "without_mask\n",
      "[0.225028   0.77497196]\n",
      "without_mask\n",
      "[0.20717928 0.79282075]\n",
      "without_mask\n",
      "[0.22601005 0.7739899 ]\n",
      "without_mask\n",
      "[0.22341071 0.7765893 ]\n",
      "without_mask\n",
      "[0.23427732 0.76572263]\n",
      "without_mask\n",
      "[0.21763158 0.7823684 ]\n",
      "without_mask\n",
      "[0.2175795 0.7824205]\n",
      "without_mask\n",
      "[0.21771912 0.78228086]\n",
      "without_mask\n",
      "[0.22704796 0.772952  ]\n",
      "without_mask\n",
      "[0.24431494 0.75568503]\n",
      "without_mask\n",
      "[0.24402979 0.7559702 ]\n",
      "without_mask\n",
      "[0.26888654 0.7311135 ]\n",
      "without_mask\n",
      "[0.27528584 0.7247141 ]\n",
      "without_mask\n",
      "[0.252449 0.747551]\n",
      "without_mask\n",
      "[0.24441896 0.755581  ]\n",
      "without_mask\n",
      "[0.25128824 0.74871176]\n",
      "without_mask\n",
      "[0.2540953 0.7459047]\n",
      "without_mask\n",
      "[0.24982493 0.7501751 ]\n",
      "without_mask\n",
      "[0.24667116 0.7533289 ]\n",
      "without_mask\n",
      "[0.2258912  0.77410877]\n",
      "without_mask\n",
      "[0.22236899 0.777631  ]\n",
      "without_mask\n",
      "[0.22642942 0.7735706 ]\n",
      "without_mask\n",
      "[0.21858677 0.78141326]\n",
      "without_mask\n",
      "[0.22849502 0.771505  ]\n",
      "without_mask\n",
      "[0.22645445 0.77354556]\n",
      "without_mask\n",
      "[0.22402813 0.77597183]\n",
      "without_mask\n",
      "[0.22622466 0.7737753 ]\n",
      "without_mask\n",
      "[0.2308921  0.76910794]\n",
      "without_mask\n",
      "[0.23479348 0.7652065 ]\n",
      "without_mask\n",
      "[0.25804403 0.74195594]\n",
      "without_mask\n",
      "[0.25572217 0.74427783]\n",
      "without_mask\n",
      "[0.2504302 0.7495698]\n",
      "without_mask\n",
      "[0.25273788 0.74726206]\n",
      "without_mask\n",
      "[0.23868082 0.76131916]\n",
      "without_mask\n",
      "[0.24346906 0.75653094]\n",
      "without_mask\n",
      "[0.234843 0.765157]\n",
      "without_mask\n",
      "[0.24415879 0.7558412 ]\n",
      "without_mask\n",
      "[0.2331206 0.7668794]\n",
      "without_mask\n",
      "[0.24041808 0.75958186]\n",
      "without_mask\n",
      "[0.2401141  0.75988585]\n",
      "without_mask\n",
      "[0.24011464 0.7598854 ]\n",
      "without_mask\n",
      "[0.24378243 0.75621754]\n",
      "without_mask\n",
      "[0.23327024 0.7667298 ]\n",
      "without_mask\n",
      "[0.2542806 0.7457194]\n",
      "without_mask\n",
      "[0.2836936  0.71630645]\n",
      "without_mask\n",
      "[0.27784526 0.72215474]\n",
      "without_mask\n",
      "[0.3167029  0.68329716]\n",
      "without_mask\n",
      "[0.32108173 0.67891824]\n",
      "without_mask\n",
      "[0.26599255 0.7340075 ]\n",
      "without_mask\n",
      "[0.2411171 0.7588829]\n",
      "without_mask\n",
      "[0.27620998 0.72379005]\n",
      "without_mask\n",
      "[0.25010213 0.74989784]\n",
      "without_mask\n",
      "[0.28017896 0.719821  ]\n",
      "without_mask\n",
      "[0.25377572 0.7462243 ]\n",
      "without_mask\n",
      "[0.26200145 0.73799855]\n",
      "without_mask\n",
      "[0.27894968 0.72105026]\n",
      "without_mask\n",
      "[0.2680598 0.7319402]\n",
      "without_mask\n",
      "[0.2496463  0.75035375]\n",
      "without_mask\n",
      "[0.25894406 0.74105597]\n",
      "without_mask\n",
      "[0.27297777 0.72702223]\n",
      "without_mask\n",
      "[0.27242735 0.7275726 ]\n",
      "without_mask\n",
      "[0.25021768 0.7497823 ]\n",
      "without_mask\n",
      "[0.25908494 0.74091506]\n",
      "without_mask\n",
      "[0.25800598 0.741994  ]\n",
      "without_mask\n",
      "[0.24826218 0.75173783]\n",
      "without_mask\n",
      "[0.28396937 0.7160306 ]\n",
      "without_mask\n",
      "[0.313502  0.6864979]\n",
      "without_mask\n",
      "[0.31512928 0.6848708 ]\n",
      "without_mask\n",
      "[0.3101396  0.68986034]\n",
      "without_mask\n",
      "[0.2921742  0.70782584]\n",
      "without_mask\n",
      "[0.28328806 0.7167119 ]\n",
      "without_mask\n",
      "[0.29867762 0.7013224 ]\n",
      "without_mask\n",
      "[0.28915843 0.7108416 ]\n",
      "without_mask\n",
      "[0.27244398 0.727556  ]\n",
      "without_mask\n",
      "[0.2701004  0.72989964]\n",
      "without_mask\n",
      "[0.2502649  0.74973506]\n",
      "without_mask\n",
      "[0.25545576 0.74454427]\n",
      "without_mask\n",
      "[0.2645738 0.7354262]\n",
      "without_mask\n",
      "[0.2609481 0.7390518]\n",
      "without_mask\n",
      "[0.25829756 0.7417024 ]\n",
      "without_mask\n",
      "[0.28251553 0.7174845 ]\n",
      "without_mask\n",
      "[0.27878702 0.721213  ]\n",
      "without_mask\n",
      "[0.27533126 0.72466874]\n",
      "without_mask\n",
      "[0.26796755 0.73203254]\n",
      "without_mask\n",
      "[0.29911846 0.7008815 ]\n",
      "without_mask\n",
      "[0.28454104 0.715459  ]\n",
      "without_mask\n",
      "[0.31758553 0.6824144 ]\n",
      "without_mask\n",
      "[0.27924317 0.7207569 ]\n",
      "without_mask\n",
      "[0.2851395 0.7148605]\n",
      "without_mask\n",
      "[0.30773464 0.6922654 ]\n",
      "without_mask\n",
      "[0.30514574 0.69485426]\n",
      "without_mask\n",
      "[0.34997523 0.6500248 ]\n",
      "without_mask\n",
      "[0.307756   0.69224393]\n",
      "without_mask\n",
      "[0.28957713 0.7104229 ]\n",
      "without_mask\n",
      "[0.29699138 0.7030086 ]\n",
      "without_mask\n",
      "[0.320076  0.6799241]\n",
      "without_mask\n",
      "[0.29143804 0.70856196]\n",
      "without_mask\n",
      "[0.2718998 0.7281002]\n",
      "without_mask\n",
      "[0.28959402 0.71040595]\n",
      "without_mask\n",
      "[0.28764367 0.71235627]\n",
      "without_mask\n",
      "[0.28899723 0.71100277]\n",
      "without_mask\n",
      "[0.2790062 0.7209938]\n",
      "without_mask\n",
      "[0.26955295 0.73044705]\n",
      "without_mask\n",
      "[0.2974696  0.70253044]\n",
      "without_mask\n",
      "[0.27351347 0.72648656]\n",
      "without_mask\n",
      "[0.316744   0.68325603]\n",
      "without_mask\n",
      "[0.30524817 0.69475186]\n",
      "without_mask\n",
      "[0.3050091  0.69499093]\n",
      "without_mask\n",
      "[0.32369944 0.6763005 ]\n",
      "without_mask\n",
      "[0.32301056 0.67698944]\n",
      "without_mask\n",
      "[0.35079187 0.6492081 ]\n",
      "without_mask\n",
      "[0.32531244 0.67468756]\n",
      "without_mask\n",
      "[0.34489632 0.6551037 ]\n",
      "without_mask\n",
      "[0.3507912 0.6492088]\n",
      "without_mask\n",
      "[0.3254567  0.67454326]\n",
      "without_mask\n",
      "[0.3798213  0.62017864]\n",
      "without_mask\n",
      "[0.38372082 0.6162791 ]\n",
      "without_mask\n",
      "[0.3723503  0.62764966]\n",
      "without_mask\n",
      "[0.36156058 0.6384394 ]\n",
      "without_mask\n",
      "[0.33431622 0.6656837 ]\n",
      "without_mask\n",
      "[0.3334794 0.6665206]\n",
      "without_mask\n",
      "[0.34698376 0.6530162 ]\n",
      "without_mask\n",
      "[0.35192123 0.64807886]\n",
      "without_mask\n",
      "[0.39373255 0.6062674 ]\n",
      "without_mask\n",
      "[0.3759819  0.62401813]\n",
      "without_mask\n",
      "[0.38619947 0.6138005 ]\n",
      "without_mask\n",
      "[0.33343464 0.66656536]\n",
      "without_mask\n",
      "[0.4031232 0.5968768]\n",
      "without_mask\n",
      "[0.35996392 0.64003605]\n",
      "without_mask\n",
      "[0.3429334  0.65706664]\n",
      "without_mask\n",
      "[0.34277278 0.6572272 ]\n",
      "without_mask\n",
      "[0.3529786 0.6470214]\n",
      "without_mask\n",
      "[0.3529786 0.6470214]\n",
      "without_mask\n",
      "[0.34937692 0.6506231 ]\n",
      "without_mask\n",
      "[0.35406202 0.645938  ]\n",
      "without_mask\n",
      "[0.32585588 0.67414415]\n",
      "without_mask\n",
      "[0.34977397 0.65022606]\n",
      "without_mask\n",
      "[0.3710208 0.6289792]\n",
      "without_mask\n",
      "[0.37755334 0.62244666]\n",
      "without_mask\n",
      "[0.36220017 0.6377998 ]\n",
      "without_mask\n",
      "[0.34862453 0.65137553]\n",
      "without_mask\n",
      "[0.38686696 0.6131331 ]\n",
      "without_mask\n",
      "[0.39063632 0.6093637 ]\n",
      "without_mask\n",
      "[0.358478 0.641522]\n",
      "without_mask\n",
      "[0.33943 0.66057]\n",
      "without_mask\n",
      "[0.3636805 0.6363195]\n",
      "without_mask\n",
      "[0.35084414 0.6491559 ]\n",
      "without_mask\n",
      "[0.30776718 0.69223285]\n",
      "without_mask\n",
      "[0.3984715  0.60152847]\n",
      "without_mask\n",
      "[0.3428496  0.65715045]\n",
      "without_mask\n",
      "[0.29769236 0.70230764]\n",
      "without_mask\n",
      "[0.33059806 0.66940194]\n",
      "without_mask\n",
      "[0.28164503 0.71835494]\n",
      "without_mask\n",
      "[0.29722834 0.7027716 ]\n",
      "without_mask\n",
      "[0.37567174 0.62432826]\n",
      "without_mask\n",
      "[0.36699998 0.6330001 ]\n",
      "without_mask\n",
      "[0.3183216 0.6816784]\n",
      "without_mask\n",
      "[0.33841726 0.6615827 ]\n",
      "without_mask\n",
      "[0.37606654 0.62393343]\n",
      "without_mask\n",
      "[0.33476612 0.66523385]\n",
      "without_mask\n",
      "[0.30684942 0.6931506 ]\n",
      "without_mask\n",
      "[0.3271573  0.67284274]\n",
      "without_mask\n",
      "[0.2970592 0.7029408]\n",
      "without_mask\n",
      "[0.33251974 0.6674803 ]\n",
      "without_mask\n",
      "[0.3472624 0.6527376]\n",
      "without_mask\n",
      "[0.3861432  0.61385673]\n",
      "without_mask\n",
      "[0.33441964 0.66558033]\n",
      "without_mask\n",
      "[0.30479202 0.69520795]\n",
      "without_mask\n",
      "[0.2732342  0.72676575]\n",
      "without_mask\n",
      "[0.27623352 0.7237665 ]\n",
      "without_mask\n",
      "[0.23445548 0.76554453]\n",
      "without_mask\n",
      "[0.24808891 0.7519111 ]\n",
      "without_mask\n",
      "[0.24935277 0.7506472 ]\n",
      "without_mask\n",
      "[0.24737047 0.75262946]\n",
      "without_mask\n",
      "[0.224597   0.77540296]\n",
      "without_mask\n",
      "[0.24085921 0.75914085]\n",
      "without_mask\n",
      "[0.25150278 0.7484972 ]\n",
      "without_mask\n",
      "[0.26191235 0.7380877 ]\n",
      "without_mask\n",
      "[0.28037065 0.71962935]\n",
      "without_mask\n",
      "[0.30629408 0.693706  ]\n",
      "without_mask\n",
      "[0.30651277 0.6934872 ]\n",
      "without_mask\n",
      "[0.28508198 0.714918  ]\n",
      "without_mask\n",
      "[0.27164078 0.7283592 ]\n",
      "without_mask\n",
      "[0.27164078 0.7283592 ]\n",
      "without_mask\n",
      "[0.29606196 0.70393807]\n",
      "without_mask\n",
      "[0.28888217 0.71111786]\n",
      "without_mask\n",
      "[0.3139654  0.68603456]\n",
      "without_mask\n",
      "[0.2888476  0.71115243]\n",
      "without_mask\n",
      "[0.31855154 0.68144846]\n",
      "without_mask\n",
      "[0.3088236 0.6911764]\n",
      "without_mask\n",
      "[0.35003224 0.64996773]\n",
      "without_mask\n",
      "[0.33146605 0.668534  ]\n",
      "without_mask\n",
      "[0.33020332 0.6697967 ]\n",
      "without_mask\n",
      "[0.33706138 0.66293865]\n",
      "without_mask\n",
      "[0.32860523 0.6713948 ]\n",
      "without_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3200945 0.6799055]\n",
      "without_mask\n",
      "[0.36663407 0.633366  ]\n",
      "without_mask\n",
      "[0.34088245 0.6591176 ]\n",
      "without_mask\n",
      "[0.31899896 0.68100107]\n",
      "without_mask\n",
      "[0.3311673 0.6688327]\n",
      "without_mask\n",
      "[0.3640564  0.63594353]\n",
      "without_mask\n",
      "[0.4254463  0.57455367]\n",
      "without_mask\n",
      "[0.35932404 0.640676  ]\n",
      "without_mask\n",
      "[0.42682576 0.5731742 ]\n",
      "without_mask\n",
      "[0.37352172 0.62647825]\n",
      "without_mask\n",
      "[0.426008 0.573992]\n",
      "without_mask\n",
      "[0.32456744 0.67543256]\n",
      "without_mask\n",
      "[0.34960344 0.6503966 ]\n",
      "without_mask\n",
      "[0.33295286 0.66704714]\n",
      "without_mask\n",
      "[0.31913507 0.6808649 ]\n",
      "without_mask\n",
      "[0.3076988 0.6923012]\n",
      "without_mask\n",
      "[0.30706906 0.69293094]\n",
      "without_mask\n",
      "[0.35838485 0.64161515]\n",
      "without_mask\n",
      "[0.27920195 0.72079813]\n",
      "without_mask\n",
      "[0.32593423 0.67406577]\n",
      "without_mask\n",
      "[0.28554648 0.7144535 ]\n",
      "without_mask\n",
      "[0.2608309  0.73916906]\n",
      "without_mask\n",
      "[0.23681833 0.7631816 ]\n",
      "without_mask\n",
      "[0.24696761 0.75303245]\n",
      "without_mask\n",
      "[0.2512642 0.7487358]\n",
      "without_mask\n",
      "[0.19673419 0.80326587]\n",
      "without_mask\n",
      "[0.22626613 0.77373385]\n",
      "without_mask\n",
      "[0.22905113 0.7709488 ]\n",
      "without_mask\n",
      "[0.22541043 0.77458954]\n",
      "without_mask\n",
      "[0.23024216 0.76975787]\n",
      "without_mask\n",
      "[0.23848827 0.76151174]\n",
      "without_mask\n",
      "[0.2106265 0.7893736]\n",
      "without_mask\n",
      "[0.21636665 0.7836333 ]\n",
      "without_mask\n",
      "[0.2202871  0.77971286]\n",
      "without_mask\n",
      "[0.22378103 0.776219  ]\n",
      "without_mask\n",
      "[0.22229551 0.7777045 ]\n",
      "without_mask\n",
      "[0.23962115 0.76037884]\n",
      "without_mask\n",
      "[0.23441674 0.7655832 ]\n",
      "without_mask\n",
      "[0.24734966 0.75265026]\n",
      "without_mask\n",
      "[0.22726117 0.77273875]\n",
      "without_mask\n",
      "[0.20370716 0.7962929 ]\n",
      "without_mask\n",
      "[0.19065548 0.8093445 ]\n",
      "without_mask\n",
      "[0.22982329 0.77017665]\n",
      "without_mask\n",
      "[0.22214709 0.7778529 ]\n",
      "without_mask\n",
      "[0.2375477 0.7624523]\n",
      "without_mask\n",
      "[0.22777706 0.7722229 ]\n",
      "without_mask\n",
      "[0.23055552 0.76944447]\n",
      "without_mask\n",
      "[0.25850806 0.7414919 ]\n",
      "without_mask\n",
      "[0.27249786 0.7275021 ]\n",
      "without_mask\n"
     ]
    }
   ],
   "source": [
    "#Test on realtime video\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "#Define our prediction dictionary\n",
    "face_classes = class_labels\n",
    "img_size = 48\n",
    "\n",
    "# Use the efficient dlib's face detector\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#I have used my webcam, one may use a '.mp4' video as well\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "#     frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    preprocessed_faces = []           \n",
    " \n",
    "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w, _ = np.shape(frame)\n",
    "    detected = detector.detectMultiScale(frame)\n",
    "    faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "   \n",
    "    if len(detected) > 0:\n",
    "        \n",
    "        for f in detected:\n",
    "            \n",
    "            # Obtain the coordinates of the detected face and draw a bounding box\n",
    "            x1, y1, w, h = [v for v in f]\n",
    "            cv2.rectangle(frame, (x1, y1), (x1+w,y1+h), (255, 0, 0), 2)\n",
    "            face =  frame[y1:y1+h, x1:x1+w, :]\n",
    "            face = cv2.resize(face, (img_rows,img_cols))\n",
    "            face = face.astype(\"float32\") / 255.0\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            preprocessed_faces.append(face)\n",
    "\n",
    "        \n",
    "        # Make predictions for the detected face \n",
    "        face_labels = []\n",
    "        for i, d in enumerate(detected):\n",
    "            preds = classifier.predict(preprocessed_faces[i])[0]\n",
    "            face_labels.append(face_classes[np.argmax(preds,axis=0)])\n",
    "            print(preds)\n",
    "        \n",
    "        # Display the results\n",
    "        for i, d in enumerate(detected):\n",
    "            label = \"{}\".format(face_labels[i])\n",
    "            print(label)\n",
    "            draw_label(frame, (x1,y1), label)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test on realtime video\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "#Define our prediction dictionary\n",
    "face_classes = class_labels\n",
    "img_size = 48\n",
    "\n",
    "# Use the efficient dlib's face detector\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#I have used my webcam, one may use a '.mp4' video as well\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "    \n",
    "frame = cv2.imread('5.jpg')\n",
    "#     frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "preprocessed_faces = []           \n",
    "\n",
    "input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "img_h, img_w, _ = np.shape(frame)\n",
    "detected = detector.detectMultiScale(frame)\n",
    "faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "\n",
    "if len(detected) > 0:\n",
    "\n",
    "    for f in detected:\n",
    "\n",
    "        # Obtain the coordinates of the detected face and draw a bounding box\n",
    "        x1, y1, w, h = [v for v in f]\n",
    "        cv2.rectangle(frame, (x1, y1), (x1+w,y1+h), (255, 0, 0), 2)\n",
    "        face =  frame[y1:y1+h, x1:x1+w, :]\n",
    "        face = cv2.resize(face, (img_rows,img_cols))\n",
    "        face = face.astype(\"float32\") / 255.0\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        preprocessed_faces.append(face)\n",
    "\n",
    "\n",
    "    # Make predictions for the detected face \n",
    "    face_labels = []\n",
    "    for i, d in enumerate(detected):\n",
    "        preds = classifier.predict(preprocessed_faces[i])[0]\n",
    "        face_labels.append(face_classes[np.argmax(preds,axis=0)])\n",
    "        print(preds)\n",
    "\n",
    "    # Display the results\n",
    "    for i, d in enumerate(detected):\n",
    "        label = \"{}\".format(face_labels[i])\n",
    "        print(label)\n",
    "        draw_label(frame, (x1,y1), label)\n",
    "\n",
    "cv2.imshow(\"Face Recognition\", frame)\n",
    "cv2.waitKey(0) == 13\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
