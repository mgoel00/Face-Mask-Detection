{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1320 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "img_rows, img_cols = 48,48\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = './dataset/train'\n",
    "validation_data_dir = './dataset/validation'\n",
    "\n",
    "# Let's use some data augmentation and define our generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "train_images = train_generator.samples\n",
    "validation_images = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'with_mask', 1: 'without_mask'}\n"
     ]
    }
   ],
   "source": [
    "#Make a dictionary for later use in predictions\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 20, 20, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               663808    \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 730,754\n",
      "Trainable params: 730,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Let us create our model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',input_shape=(img_rows,img_cols,3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 4.4944 - acc: 0.5427 - val_loss: 0.8598 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.85979, saving model to mask_detector.h5\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 0.7645 - acc: 0.5740 - val_loss: 0.6186 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.85979 to 0.61863, saving model to mask_detector.h5\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 0.6621 - acc: 0.6288 - val_loss: 0.4730 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61863 to 0.47296, saving model to mask_detector.h5\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 12s 150ms/step - loss: 0.6245 - acc: 0.6761 - val_loss: 0.4329 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47296 to 0.43286, saving model to mask_detector.h5\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 12s 148ms/step - loss: 0.6333 - acc: 0.6685 - val_loss: 0.4190 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.43286 to 0.41895, saving model to mask_detector.h5\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 12s 147ms/step - loss: 0.5942 - acc: 0.7028 - val_loss: 0.2768 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41895 to 0.27684, saving model to mask_detector.h5\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 0.5581 - acc: 0.7317 - val_loss: 0.2298 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27684 to 0.22977, saving model to mask_detector.h5\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 12s 149ms/step - loss: 0.5408 - acc: 0.7447 - val_loss: 0.2688 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22977\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 12s 151ms/step - loss: 0.4784 - acc: 0.7828 - val_loss: 0.1125 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22977 to 0.11252, saving model to mask_detector.h5\n",
      "Epoch 10/10\n",
      "47/82 [================>.............] - ETA: 5s - loss: 0.4525 - acc: 0.7912"
     ]
    }
   ],
   "source": [
    "#Training our model\n",
    "#This model has been trained only for one epoch. One could do some tweakings!\n",
    "from keras.optimizers import RMSprop, SGD,Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"mask_detector.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "nb_train_samples = train_images\n",
    "nb_validation_samples = validation_images\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'rmsprop',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
